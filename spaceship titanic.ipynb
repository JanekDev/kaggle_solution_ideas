{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spaceship Titanic ðŸš€\n",
    "This notebook is an exercise in exploratory data analysis and machine learning. It uses the [Spaceship Titanic](https://www.kaggle.com/c/spaceship-titanic) data set, which contains information about the passengers's fate on the futuristic spaceship Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "First, we will import the necessary libraries, load the data, and survey basic information about the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "train_set = pd.read_csv('train.csv')\n",
    "test_set = pd.read_csv('test.csv')\n",
    "\n",
    "train = train_set.copy()\n",
    "test = test_set.copy()\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Check the dataset details, missing values, datatypes and other information.\n",
    "It will allow us to further choose the examination methods determine exploration strategy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the 'Transported' column data distribution\n",
    "sns.countplot(x='Transported', data=train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.dtypes ### check the data type of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the features are of type `object` and `int64` -  the first ones are categorical types, the latter is a numerical type.\n",
    "The dataset description is available in the [Kaggle dataset description](https://www.kaggle.com/c/spaceship-titanic/data).\n",
    "The columns are as follows:\n",
    "- **PassengerId** - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "\n",
    "- **HomePlanet** - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "\n",
    "- **CryoSleep** - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "\n",
    "- **Cabin** - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "\n",
    "- **Destination** - The planet the passenger will be debarking to.\n",
    "\n",
    "- **Age** - The age of the passenger.\n",
    "\n",
    "- **VIP** - Whether the passenger has paid for special VIP service during the voyage.\n",
    "\n",
    "- **RoomService, FoodCourt, ShoppingMall, Spa, VRDeck** - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "\n",
    "- **Name** - The first and last names of the passenger.\n",
    "\n",
    "- **Transported** - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.isnull().sum() ### check the missing value of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.isnull().sum()/train_set.shape[0]*100 ### check the percentage of missing value of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.describe() ### check the statistical summary of each column (from the numerical columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Check the data distribution, correlation and mutual information of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the names of numerical and categorical columns\n",
    "numerical_cols, categorical_cols = train_set.dtypes[train_set.dtypes != 'object'].index, train_set.dtypes[train_set.dtypes == 'object'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the correlation matrix of numerical columns\n",
    "corr_matrix = train_set.corr()\n",
    "corr_matrix.style.background_gradient() ### check the correlation matrix of numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spa + VRDeck, FoodCourt + Shopping Mall, RoomService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=train_set,x='HomePlanet', hue='Transported') ### check the distribution of home planet and transported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check age distribution with division by transported column\n",
    "sns.violinplot(x='Transported', y='Age', data=train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### group people into bins and check the distribution of age with transported column\n",
    "bins = [0, 15, 20, 30, 40, 50, 60, 100]\n",
    "group_names = ['0-15', '16-20', '21-30', '31-40', '41-50', '51-60', '61-100']\n",
    "train_set['AgeGroup'] = pd.cut(train_set['Age'], bins, labels=group_names)\n",
    "sns.histplot(hue='Transported', x='AgeGroup', data=train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=train_set, x='CryoSleep', hue='Transported') ### check the distribution of survived and transported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test the cabin split hypothesis\n",
    "hypo = train_set[['Cabin','Transported']].copy()\n",
    "hypo[['Deck', 'Num', 'Side']] = hypo['Cabin'].str.split('/', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Deck', data=hypo, hue='Transported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Side', data=hypo, hue='Transported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=train_set,x='VIP', hue='Transported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ammenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'] ### room service seem to be distinguishable from other amenities, RS, FC\n",
    "# we can sum 3 vars\n",
    "# #FC Spa VR somewhat correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline with column transformer and model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, train['Transported'], test_size=0.2, random_state=42)\n",
    "\n",
    "class spaceship_titanic_transformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        df[['Deck', 'Num', 'Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "        bins = [0, 15, 20, 30, 40, 50, 60, 100]\n",
    "        group_names = ['0-15', '16-20', '21-30', '31-40', '41-50', '51-60', '61-100']\n",
    "        df['AgeGroup'] = pd.cut(df['Age'], bins, labels=group_names)\n",
    "        df['SpaVR'] = df['Spa']+df['VRDeck']\n",
    "        df['FoodMall'] = df['FoodCourt']+df['ShoppingMall']\n",
    "        df.drop(['PassengerId', 'Name', 'Cabin', 'Spa', 'VRDeck', 'FoodCourt', 'ShoppingMall'] , axis=1, inplace=True)\n",
    "        return df\n",
    "        \n",
    "\n",
    "\n",
    "#numerical transformer\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "#categorical transformer\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#preprocessing pipeline\n",
    "column_tranformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, ['SpaVR', 'FoodMall', 'RoomService']),\n",
    "        ('cat', categorical_transformer, ['Deck', 'Num', 'Side', 'AgeGroup', 'VIP', 'CryoSleep', 'HomePlanet'])\n",
    "    ])\n",
    "\n",
    "\n",
    "ml_pipeline = Pipeline(steps=[('preprocessor', spaceship_titanic_transformer()),\n",
    "    ('column_transformer', column_tranformer),\n",
    "    ('classifier', XGBClassifier())])\n",
    "\n",
    "# search for hyperparameters by grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 500, 1000],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(ml_pipeline, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# check the best parameters\n",
    "print(grid_search.best_params_)\n",
    "# get the best estimator accuracy\n",
    "print(grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test['PassengerId'] + grid_search.predict(test)\n",
    "predictions = pd.DataFrame(predictions, columns=['PassengerId'])\n",
    "predictions.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP',\n",
    "       'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
    "       'Transported', 'Age_Group', 'AgeGroup', 'Deck', 'Num', 'Side', 'SpaVR',\n",
    "       'FoodMall'],"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79be5273dd2a4b10d2c1f0e02d55929a76c8c0f215cdd8360fa7ff2fae9a0653"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
